{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  The CrewAI Jupyter Notebook (eHjerteRehab.ipynb)\n",
    "\n",
    "\n",
    "A.L. 2025-05-24 (with Gemini 2.5 Pro Preview and DeepResearch)\n",
    "\n",
    "Using the `ehjerterehab_crew_env` defined in environment.yml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jupyter Notebook, developed within the Cursor.ai IDE, would be structured with alternating code cells and Markdown cells for annotations. Below is a description of its key components:\n",
    "\n",
    "(Markdown Cell - Annotation)\n",
    "\n",
    "Title: eHjerteRehab: Simplified Patient Data Triage with CrewAI\n",
    "Introduction: Briefly explain the purpose of the notebook – to demonstrate a basic multi-agent workflow for analyzing simulated patient data using CrewAI. Mention the agents and their roles.\n",
    "(Code Cell - Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_google_genai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m load_dotenv()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Configure the LLM (Example using OpenAI)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Ensure OPENAI_API_KEY is set in your.env file or environment\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# from langchain_openai import ChatOpenAI\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# For Google Gemini (ensure GOOGLE_API_KEY is set):\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[1;32m     16\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatGoogleGenerativeAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-flash-latest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m                              verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m                              temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m     19\u001b[0m                              google_api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGOOGLE_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# (Optional) Instantiate any tools if needed globally\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# e.g., code_interpreter_tool = CodeInterpreterTool(llm=llm)\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_google_genai'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import CodeInterpreterTool # Or other relevant tools like CSVSearchTool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables (for API keys)\n",
    "load_dotenv()\n",
    "\n",
    "# Configure the LLM (Example using OpenAI)\n",
    "# Ensure OPENAI_API_KEY is set in your.env file or environment\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "# For Google Gemini (ensure GOOGLE_API_KEY is set):\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\",\n",
    "                             verbose=True,\n",
    "                             temperature=0.2,\n",
    "                             google_api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# (Optional) Instantiate any tools if needed globally\n",
    "# e.g., code_interpreter_tool = CodeInterpreterTool(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Markdown Cell - Annotation)\n",
    "\n",
    "Explain the imports: Agent, Task, Crew, Process are core CrewAI components. CodeInterpreterTool allows agents to execute Python code. dotenv is for managing API keys.   \n",
    "Explain LLM configuration: CrewAI agents need an LLM for reasoning. Show an example (OpenAI or Gemini). Emphasize setting API keys securely via environment variables.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Markdown Cell - Annotation)\n",
    "\n",
    "Simulated Patient Data: Describe the structure of the input data for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated patient data for the demo\n",
    "patient_data_input =\n",
    "\n",
    "# Convert to a string format that can be easily passed to the first agent\n",
    "patient_data_summary_str = \"\\n\".join([str(p) for p in patient_data_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Markdown Cell - Annotation)\n",
    "\n",
    "Explain that this is simplified data for demonstration. In a real system, data would come from databases or APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Markdown Cell - Annotation)\n",
    "\n",
    "Agent Definitions: Detail the role, goal, and backstory for each agent.\n",
    "(Code Cell - Agent Definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Vital Signs Analyzer Agent\n",
    "vital_signs_analyzer = Agent(\n",
    "    role='Vital Signs Monitoring Specialist',\n",
    "    goal='Analyze patient vital signs data (resting HR, steps) to identify and flag any readings that are concerning. Resting HR > 90 bpm is high. Total steps < 2000 is low.',\n",
    "    backstory='An AI assistant dedicated to meticulously reviewing numerical health data from cardiac rehabilitation patients, trained to spot deviations that might require further attention.',\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    allow_delegation=False\n",
    "    # tools=[code_interpreter_tool] # If using CodeInterpreterTool instantiated globally\n",
    ")\n",
    "\n",
    "# Define the Symptom Checker Agent\n",
    "symptom_checker = Agent(\n",
    "    role='Patient Symptom Screener',\n",
    "    goal=\"Review patient-reported textual symptoms to identify and flag mentions of critical keywords such as 'chest pain', 'dizzy', 'dizziness', 'severe discomfort', 'palpitations', 'faint'.\",\n",
    "    backstory='An AI assistant focused on understanding patient language, specifically trained to detect urgent symptom descriptions in cardiac patient reports.',\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    allow_delegation=False\n",
    ")\n",
    "\n",
    "# Define the Clinical Reporter Agent\n",
    "clinical_reporter = Agent(\n",
    "    role='Clinical Summary Generator',\n",
    "    goal='Compile the findings from vital signs analysis and symptom checking into a concise Markdown report. The report should list each patient, any flagged vital signs with values, and any flagged symptoms. If no flags for a patient, state \"No immediate concerns noted\".',\n",
    "    backstory='An AI assistant skilled in synthesizing analytical information from multiple sources and presenting it clearly and efficiently in Markdown format for healthcare professionals.',\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    allow_delegation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Markdown Cell - Annotation)\n",
    "\n",
    "Explain each agent's configuration: role, goal, backstory shape its behavior. llm assigns the language model. verbose=True is crucial for observing the agent's thought process during development and debugging, as it reveals the internal \"ReAct\" (Reasoning and Acting) loop – the agent's thoughts, the action it decides upon, the input to that action, and the subsequent observation. allow_delegation=False is set for simplicity in this demo.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Markdown Cell - Annotation)\n",
    "\n",
    "Task Definitions: Detail the description and expected output for each task, assigning it to the respective agent.\n",
    "(Code Cell - Task Definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the task for analyzing vital signs\n",
    "vital_analysis_task = Task(\n",
    "    description=(\n",
    "        \"Analyze the following patient data summaries for vital signs concerns:\\n\"\n",
    "        \"------\\n\"\n",
    "        \"{patient_data_input_str}\\n\"\n",
    "        \"------\\n\"\n",
    "        \"Identify patients with resting heart rate (avg_resting_hr_last_24h) > 90 bpm OR total steps (total_steps_last_24h) < 2000. \"\n",
    "        \"For each patient, list their ID and the specific vital sign(s) that are flagged with their values.\"\n",
    "        \"If no vital signs are flagged for a patient, note that.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A textual summary listing each patient ID and any flagged vital signs with their values, or a note if no vital signs are flagged for that patient.\"\n",
    "    ),\n",
    "    agent=vital_signs_analyzer\n",
    ")\n",
    "\n",
    "# Define the task for checking symptoms\n",
    "symptom_check_task = Task(\n",
    "    description=(\n",
    "        \"Analyze the 'reported_symptoms_text' for each patient in the following data summaries:\\n\"\n",
    "        \"------\\n\"\n",
    "        \"{patient_data_input_str}\\n\"\n",
    "        \"------\\n\"\n",
    "        \"Identify patients who report symptoms containing keywords: 'chest pain', 'dizzy', 'dizziness', 'severe discomfort', 'palpitations', 'faint'. \"\n",
    "        \"For each patient, list their ID and the exact flagged symptom text.\"\n",
    "        \"If no critical symptoms are reported for a patient, note that.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A textual summary listing each patient ID and any reported critical symptoms, or a note if no critical symptoms are reported for that patient.\"\n",
    "    ),\n",
    "    agent=symptom_checker\n",
    ")\n",
    "\n",
    "# Define the task for generating the report\n",
    "reporting_task = Task(\n",
    "    description=(\n",
    "        \"Combine the vital signs analysis and symptom check analysis into a single, concise Markdown report. \"\n",
    "        \"The report should have a section for each patient. \"\n",
    "        \"For each patient, clearly state their ID, then list any flagged vital signs (with values) from the vital signs analysis, \"\n",
    "        \"and any flagged symptoms from the symptom check analysis. \"\n",
    "        \"If a patient has no flags from either analysis, state 'No immediate concerns noted for this patient.' \"\n",
    "        \"Ensure the final output is ONLY the Markdown report, ready for display.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A comprehensive Markdown report summarizing all findings for each patient. \"\n",
    "        \"Example for one patient:\\n\"\n",
    "        \"### Patient ID: P00X\\n\"\n",
    "        \"- Flagged Vital Signs: Resting HR: 95 bpm, Total Steps: 1500\\n\"\n",
    "        \"- Flagged Symptoms: Reported 'chest pain during activity'.\\n\"\n",
    "        \"(If no flags: ### Patient ID: P00Y\\n - No immediate concerns noted for this patient.)\"\n",
    "    ),\n",
    "    agent=clinical_reporter,\n",
    "    context=[vital_analysis_task, symptom_check_task] # Depends on the output of the previous two tasks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Markdown Cell - Annotation)\n",
    "\n",
    "Explain task parameters: description provides instructions to the agent. expected_output guides the agent on the desired format of its result. agent links the task to an agent. context specifies that reporting_task uses outputs from vital_analysis_task and symptom_check_task.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Markdown Cell - Annotation)\n",
    "\n",
    "Crew Instantiation and Kickoff: Show how to assemble the crew and run it.\n",
    "(Code Cell - Crew Execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the crew with a sequential process\n",
    "ehjerterehab_crew = Crew(\n",
    "    agents=[vital_signs_analyzer, symptom_checker, clinical_reporter],\n",
    "    tasks=[vital_analysis_task, symptom_check_task, reporting_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=2 # Use 2 for detailed crew-level logging\n",
    ")\n",
    "\n",
    "# Kick off the crew's work\n",
    "# The input dictionary key 'patient_data_input_str' must match the placeholder in the task descriptions\n",
    "results = ehjerterehab_crew.kickoff(inputs={'patient_data_input_str': patient_data_summary_str})\n",
    "\n",
    "# Print the final result from the crew\n",
    "print(\"\\n\\n--- Final Report ---\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Markdown Cell - Annotation)\n",
    "\n",
    "Explain crew creation: agents and tasks lists define the crew members and their work. process=Process.sequential means tasks run in order. verbose=2 provides detailed logs of the crew's execution flow.   \n",
    "Explain kickoff(): This starts the crew's execution. The inputs dictionary provides initial data to the tasks that have matching placeholders (e.g., {patient_data_input_str}).   \n",
    "Describe the expected output: A Markdown formatted report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5. Interpreting the Output and Next Steps\n",
    "The output from this demo crew will be a Markdown-formatted string containing the clinical summary report. It should list each patient from the simulated data, highlighting any flagged vital signs (e.g., \"Patient P002: Flagged Vital Signs: Resting HR: 98 bpm, Total Steps: 1800\") and any critical reported symptoms (e.g., \"Patient P002: Flagged Symptoms: Woke up with some chest pain, but it passed. Feeling a bit dizzy today.\"). Patients with no flags would be noted as having \"No immediate concerns.\"\n",
    "\n",
    "This simple prototype demonstrates the fundamental capability of CrewAI to orchestrate multiple AI agents to perform a multi-step analysis and reporting task relevant to eHjerteRehab.\n",
    "\n",
    "Next Steps for Expansion:\n",
    "This basic prototype can be significantly expanded to move closer to the comprehensive eHjerteRehab agent system envisioned:\n",
    "\n",
    "Real Data Integration: Connect agents to actual data sources (databases, APIs for wearables, EHRs) using appropriate crewai_tools (e.g., DatabaseTool, custom API tools) instead of simulated data.\n",
    "Sophisticated Tools: Equip agents with more advanced tools. For instance, the Risk Assessment Agent could use the CodeInterpreterTool to run complex ML models for risk scoring, or a custom tool that queries a medical knowledge graph. The SymptomCheckerAgent could use tools leveraging more advanced NLP models for nuanced symptom understanding rather than simple keyword matching.\n",
    "More Specialized Agents: Introduce additional agents as outlined in Section 1.3 (e.g., a PersonalizedContentAgent that uses the report from the ClinicalReporterAgent to suggest interventions).\n",
    "Hierarchical Process: For more complex patient management scenarios, implement a Process.hierarchical model where a \"ClinicalManagerAgent\" coordinates the other agents, assigns tasks dynamically, and reviews outputs before final action.\n",
    "Robust Error Handling: Implement comprehensive error handling within agent tasks and tool interactions to manage API failures, data inconsistencies, or unexpected LLM outputs.\n",
    "State Management: For long-running interactions or more complex patient journeys, incorporate more sophisticated state management to maintain context across multiple crew executions or patient interactions.\n",
    "Integration with MLOps: If agents utilize ML models (e.g., for risk prediction), integrate the system with MLOps pipelines for model versioning, monitoring for performance degradation or data drift, and facilitating retraining cycles. This is critical for maintaining the accuracy and reliability of AI-driven insights in a production healthcare environment. Moving from a Jupyter notebook demonstration to a production-grade eHjerteRehab system requires careful consideration of these operational aspects, which are beyond the scope of a simple kickoff() but are essential for the technical manager to plan for in the actual deployment of the eHjerteRehab project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "Recap of AI's Transformative Impact on eHjerteRehab\n",
    "The integration of Artificial Intelligence holds the promise of fundamentally transforming cardiac eRehabilitation platforms like eHjerteRehab. As explored, AI agents, orchestrated by frameworks such as CrewAI, can create a collaborative intelligence layer capable of automating complex monitoring, analysis, and communication tasks. Advanced data analysis, powered by machine learning techniques for pattern recognition in physiological and behavioral data, and natural language processing for understanding patient narratives, can unlock deeper, more nuanced insights into each patient's unique condition and progress. Furthermore, AI-driven communication tools, including intelligent clinician dashboards and personalized patient feedback systems, can make the rehabilitation journey more efficient for clinicians and more engaging and supportive for patients. Collectively, these AI methodologies can shift eHjerteRehab from a static content delivery platform to a dynamic, adaptive, and proactive system that offers truly personalized care, enhances patient adherence, and ultimately aims to improve clinical outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future Outlook and Recommendations for AI Integration\n",
    "The journey towards a fully AI-integrated eHjerteRehab platform should be approached strategically and incrementally.\n",
    "\n",
    "Phased Implementation: It is advisable to begin with foundational AI capabilities. This could involve establishing robust data collection pipelines for wearables and PROs, followed by the development of initial AI agents for data monitoring and basic risk flagging (similar to the prototype). Subsequently, more sophisticated analytical models (ML for predictive risk, NLP for feedback analysis) and more autonomous agent functionalities (e.g., personalized content suggestion, hierarchical task management) can be progressively layered into the system.\n",
    "Ethical Considerations and Data Governance: Throughout the development and deployment lifecycle, paramount importance must be given to ethical considerations, patient data privacy, and security. Compliance with healthcare data regulations (e.g., GDPR, HIPAA) is non-negotiable. Transparent policies regarding data usage and AI decision-making processes should be established.\n",
    "Human-in-the-Loop (HITL) as a Core Principle: Especially for clinical decision support and patient communication involving medical advice, the HITL principle must be embedded. AI should augment, not replace, human clinicians. Mechanisms for clinician review, override, and validation of AI-generated insights or recommendations are crucial for ensuring patient safety and maintaining trust in the system.\n",
    "Continuous Learning and Adaptation: The field of AI is rapidly evolving. The eHjerteRehab platform should be designed with adaptability in mind, allowing for the integration of new AI techniques, tools, and models as they mature and demonstrate value. This includes establishing processes for ongoing monitoring of AI model performance, retraining as necessary, and gathering feedback from both clinicians and patients to iteratively refine the AI components.\n",
    "Focus on Explainability (XAI): To foster clinician adoption and trust, efforts should be made to incorporate XAI techniques, particularly for AI components involved in risk assessment or clinical recommendations. Understanding the \"why\" behind an AI's output is critical in healthcare.\n",
    "By embracing these principles, eHjerteRehab can harness the transformative power of AI to deliver a new generation of cardiac eRehabilitation that is more personalized, proactive, efficient, and ultimately, more effective in supporting patients on their journey to recovery and long-term cardiovascular health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cloud.google.com\n",
    "What are AI agents? Definition, examples, and types | Google Cloud\n",
    "Opens in a new window\n",
    "\n",
    "github.com\n",
    "stephenc222/example-crewai: Example project demonstrating CrewAI - GitHub\n",
    "Opens in a new window\n",
    "\n",
    "docs.crewai.com\n",
    "Tasks - CrewAI\n",
    "Opens in a new window\n",
    "\n",
    "aimasterclass.com\n",
    "What is Collaborative Multi-Agent Systems? - AI Master Class\n",
    "Opens in a new window\n",
    "\n",
    "docs.crewai.com\n",
    "Crafting Effective Agents - CrewAI\n",
    "Opens in a new window\n",
    "\n",
    "github.com\n",
    "crewAI-examples/prep-for-a-meeting/main.py at main - GitHub\n",
    "Opens in a new window\n",
    "\n",
    "news-medical.net\n",
    "Mayo Clinic develops AI tool to visualize complex biological data - News-Medical.net\n",
    "Opens in a new window\n",
    "\n",
    "quadratichq.com\n",
    "The Importance of AI Data Analysis in Healthcare - Quadratic\n",
    "Opens in a new window\n",
    "\n",
    "thoughtful.ai\n",
    "How AI-Powered Solutions Enhance Patient Experience - Thoughtful AI\n",
    "Opens in a new window\n",
    "\n",
    "pinc-ai.com\n",
    "Clinical Decision Support Analytics - Stanson Health - PINC AI\n",
    "Opens in a new window\n",
    "\n",
    "lumenalta.com\n",
    "9 examples of natural language processing in healthcare | NLP in healthcare - Lumenalta\n",
    "Opens in a new window\n",
    "\n",
    "eithealth.eu\n",
    "Machine learning in healthcare: Uses, benefits and pioneers in the field - EIT Health\n",
    "Opens in a new window\n",
    "\n",
    "relias.com\n",
    "AI in Patient Experience: Top 4 AI Use Cases in Healthcare | Relias\n",
    "Opens in a new window\n",
    "\n",
    "akira.ai\n",
    "How AI Agents are Transforming Rehabilitation Monitoring in ...\n",
    "Opens in a new window\n",
    "\n",
    "digiqt.com\n",
    "Is Your Clinic Ready for AI Agents in Physical Therapy? | Digiqt Blog\n",
    "Opens in a new window\n",
    "\n",
    "getondata.com\n",
    "AI-powered dashboards for healthcare: The modern medical edge\n",
    "Opens in a new window\n",
    "\n",
    "reddit.com\n",
    "What programs and software do I need to get started? : r/crewai\n",
    "Opens in a new window\n",
    "\n",
    "foreseemed.com\n",
    "Machine Learning in Healthcare: Guide to Applications & Benefits\n",
    "Opens in a new window\n",
    "\n",
    "pmc.ncbi.nlm.nih.gov\n",
    "Natural Language Processing to Extract Meaningful Information from ...\n",
    "Opens in a new window\n",
    "\n",
    "community.crewai.com\n",
    "Suggested cursorrules template for working with CrewAI - General ...\n",
    "Opens in a new window\n",
    "\n",
    "cohorte.co\n",
    "The Friendly Developer's Guide to CrewAI for Support Bots & Workflow Automation\n",
    "Opens in a new window\n",
    "\n",
    "basishealth.io\n",
    "Personalized Health Dashboards: Design Guide & Best Practices | Basis Blog\n",
    "Opens in a new window\n",
    "\n",
    "mdpi.com\n",
    "Deep Learning for Predicting Rehabilitation Success: Advancing Clinical and Patient-Reported Outcome Modeling - MDPI\n",
    "Opens in a new window\n",
    "\n",
    "app.uxcel.com\n",
    "Dashboard Design for Health Platform Brief - Uxcel\n",
    "Opens in a new window\n",
    "\n",
    "researchgate.net\n",
    "Machine Learning-Based Prediction Models for Healthcare Outcomes in Patients Participating in Cardiac Rehabilitation: A Systematic Review | Request PDF - ResearchGate\n",
    "Opens in a new window\n",
    "\n",
    "alejandro-ao.com\n",
    "Crew AI Crash Course (Step by Step) - Alejandro AO\n",
    "Opens in a new window\n",
    "\n",
    "inspireresearch.com\n",
    "Inspire Launches AI-Enabled Patient Insights | Transforming Life Sciences Research\n",
    "Opens in a new window\n",
    "\n",
    "okoone.com\n",
    "What generative AI means for the future of healthcare | Okoone\n",
    "Opens in a new window\n",
    "\n",
    "thoughtspot.com\n",
    "The Human-in-the-Loop Approach: Bridging AI & Human Expertise - ThoughtSpot\n",
    "Opens in a new window\n",
    "\n",
    "1000minds.com\n",
    "What is Human-in-the-loop (HITL) in AI-assisted decision-making? - 1000minds\n",
    "Opens in a new window\n",
    "\n",
    "github.com\n",
    "generative-ai/gemini/agent-engine ... - GitHub\n",
    "Opens in a new window\n",
    "\n",
    "docs.crewai.com\n",
    "Quickstart - CrewAI\n",
    "Opens in a new window\n",
    "\n",
    "ai.google.dev\n",
    "Customer Support Analysis with Gemini 2.5 Pro and CrewAI\n",
    "Opens in a new window\n",
    "\n",
    "mdpi.com\n",
    "Comparative Analysis of Machine Learning Techniques for Heart Rate Prediction Employing Wearable Sensor Data - MDPI\n",
    "Opens in a new window\n",
    "\n",
    "ascopubs.org\n",
    "Using Machine Learning to Predict Unplanned Hospital Utilization and Chemotherapy Management From Patient-Reported Outcome Measures | JCO Clinical Cancer Informatics - ASCO Publications\n",
    "Opens in a new window\n",
    "\n",
    "researchgate.net\n",
    "Comparative Analysis of Machine Learning Techniques for Heart Rate Prediction Employing Wearable Sensor Data - ResearchGate\n",
    "Opens in a new window\n",
    "\n",
    "ibm.com\n",
    "What is crewAI? - IBM\n",
    "Opens in a new window\n",
    "\n",
    "docs.crewai.com\n",
    "Processes - CrewAI\n",
    "Opens in a new window\n",
    "\n",
    "pmc.ncbi.nlm.nih.gov\n",
    "Population-Based Applications and Analytics Using Patient-Reported Outcome Measures - PMC - PubMed Central\n",
    "Opens in a new window\n",
    "\n",
    "docs.crewai.com\n",
    "Agents - CrewAI\n",
    "Opens in a new window\n",
    "\n",
    "docs.crewai.com\n",
    "Build Your First Crew - CrewAI\n",
    "Opens in a new window\n",
    "\n",
    "researchgate.net\n",
    "(PDF) Creating a Comprehensive AI-Driven Risk Stratification Tool for High-Risk Heart Failure Populations - ResearchGate\n",
    "Opens in a new window\n",
    "\n",
    "arkenea.com\n",
    "3 Compelling Cases of AI-Driven Patient Risk Stratification Tools - Arkenea\n",
    "Opens in a new window\n",
    "\n",
    "beyondkey.com\n",
    "Healthcare Dashboard Examples | Beyond Key\n",
    "Opens in a new window\n",
    "\n",
    "github.com\n",
    "alexfazio/crewAI-quickstart: A collection of notebooks ... - GitHub\n",
    "Opens in a new window\n",
    "\n",
    "aws.amazon.com\n",
    "Build agentic systems with CrewAI and Amazon Bedrock | AWS ...\n",
    "Opens in a new window\n",
    "\n",
    "uibakery.io\n",
    "10 Free Healthcare Dashboard Templates for Medical Data Management | UI Bakery Blog\n",
    "Opens in a new window\n",
    "\n",
    "upsolve.ai\n",
    "10 Healthcare Dashboard Examples + Key Metrics To Track in 2025 - Upsolve AI\n",
    "Opens in a new window\n",
    "\n",
    "jmai.amegroups.org\n",
    "Development and validation of a data visualization dashboard for automatic pain assessment and artificial intelligence analyses in cancer patients\n",
    "Opens in a new window\n",
    "\n",
    "thebricks.com\n",
    "Clinical and Psychosocial Profile Dashboard Template - Bricks\n",
    "Opens in a new window\n",
    "\n",
    "Sources read but not used in the report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hjerterehab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
